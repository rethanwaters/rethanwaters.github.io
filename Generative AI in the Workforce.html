<!DOCTYPE html>
<!-- saved from url=(0022)http://127.0.0.1:8000/ -->
<html lang="en" data-bs-theme="light" style="scroll-padding-top: 76px;"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="None">
        
        <link rel="canonical" href="http://127.0.0.1:8000/">
        <link rel="shortcut icon" href="http://127.0.0.1:8000/img/favicon.ico">
        <title>Generative AI in the Workforce</title>
        <link href="./Generative AI in the Workforce_files/bootstrap.min.css" rel="stylesheet">
        <link href="./Generative AI in the Workforce_files/fontawesome.min.css" rel="stylesheet">
        <link href="./Generative AI in the Workforce_files/brands.min.css" rel="stylesheet">
        <link href="./Generative AI in the Workforce_files/solid.min.css" rel="stylesheet">
        <link href="./Generative AI in the Workforce_files/v4-font-face.min.css" rel="stylesheet">
        <link href="./Generative AI in the Workforce_files/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="./Generative AI in the Workforce_files/github.min.css">
        <link id="hljs-dark" rel="stylesheet" href="./Generative AI in the Workforce_files/github-dark.min.css" disabled="">
        <script src="./Generative AI in the Workforce_files/highlight.min.js.download"></script>
        <script>hljs.highlightAll();</script> 
        <script src="https://cdn.jsdelivr.net/gh/ncase/nutshell/nutshell.js"></script>
        <script>
            Nutshell.setOptions({
                dontEmbedHeadings: true
            });
            </script>
        <style>
            .nutshell-heading{
                margin-bottom: 6px;
            }
        </style>

    </head>

    <body class="homepage">
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="#generative-ai-use-in-the-workforce">Generative AI in the Workforce</a>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#generative-ai-use-in-the-workforce" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                    </ul>
                </div>s
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary" style="top: 76px;">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#generative-ai-use-in-the-workforce" class="nav-link active">Generative AI Use In The Workforce</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#introduction" class="nav-link">Introduction</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#what-is-generative-ai" class="nav-link">What is Generative AI?</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#what-are-the-potential-use-cases-of-generative-ai" class="nav-link">What Are the Potential Use Cases of Generative AI?</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#how-is-generative-ai-being-used-now" class="nav-link">How Is Generative AI Being Used Now?</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#why-hasnt-generative-ai-caught-on-in-the-workplace-yet" class="nav-link">Why Hasn't Generative AI Caught On In the Workplace Yet?</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#what-is-the-future-of-generative-ai" class="nav-link">What is the Future of Generative AI?</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#bibliography" class="nav-link">Bibliography</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
<div class="col-md-9" role="main">

<h1 id="generative-ai-use-in-the-workforce">Generative AI Use In The Workforce</h1>
<h4 id="by-roland-waterson">By Roland Waterson</h4>
<p><br></p>

<h2>Preface</h2>
<p>Hi! Thank you for reading this paper. As an experiment in hopes of making this paper feel more interactive and engaging, 
    I've included some expandable explanations that allow you to pick and choose how you'd like to read this paper. 
    You can access them by clicking on links that look like <a href="#Testing">:this</a>. These are called nutshells, and 
    they've been created by the wonderful Nicky Case. You can learn more about them and this package over <a href="https://ncase.me/nutshell/">:here</a>! </p>

<h2>:x Testing</h2>
<p>Yep, just like that!</p>


<!-- Introduction -->
<h2 id="introduction">Introduction</h2>
<p>It only feels like yesterday that ChatGPT was released for general public use on November 30th, 2022. The predictive text model sparked a renewed, burning interest in the potential <a href="#PotentialUseCases">:use cases</a> of generative AIs (Fui-Hoon, 3). 
    The field of generative AI quickly became a Wild West, with new use cases being discovered by the week. </p>
<p><img alt="A sample prompt and response from ChatGPT-4o, by the author" src="./Generative AI in the Workforce_files/fig1.png"></p>
<p><em>Fig 1: A sample prompt and response from ChatGPT-4o, by the author</em></p>
<p>Great enthusiasm, however, is usually followed by great skepticism. While some were quick to dismiss generative AI as just an overly-hyped shiny new amusement, others harbored deeper worries. Frequent hallucinations, biased responses, and lack of transparency were only some of the concerns that topped the list (Frey, 11). Although many companies were eager to integrate generative AI into their business to capitalize on its potential, few were willing to fully commit to using these tools because of the concerns mentioned earlier. With the use of generative AI only increasing, we must address how we can integrate these tools within the workplace safely and efficiently. This paper aims to answer this question by first defining what generative AI actually is, what are the proposed and currently implemented use cases in the workplace, and what are some of the hurdles we must overcome in the future. </p>

<h2>:x Potential Use Cases</h2>
<p>Not only was ChatGPT able to answer prompts with an unprecedented human-like response, 
    but it was also able to generate rudimentary code, write poetry, and perform a myriad of tasks that was previously thought to be only possible through human intelligence. 
    The widespread adoption of ChatGPT started a wave of countless other generative AIs, including <a href='https://en.wikipedia.org/wiki/Midjourney'>:Midjourney</a> for text-to-image generation, GitHub Copilot for coding assistance, and Suno for music composition. 
</p>



<!-- Header 1 -->
<h2 id="what-is-generative-ai">What is Generative AI?</h2>
<p>Before we can talk about generative AIs, we need to first understand what an AI actually is, and how generative AIs differ from their predecessors. Simply put, AIs are computer programs - the "artificial" part - that are designed to accomplish some task that would require some intelligence - the "intelligence" part. AIs have been around for more than 50 years, all with wildly different purposes. For example, ELIZA (which can be thought of as the ancestor of ChatGPT) was created all the way back in 1966. It was able to provide responses to questions based on Rogerian psychotherapy, but a human could tell that a machine generated the responses (Frey, 2). Not all AIs were focused on creating human-like responses, however. In 1997, the advanced AI Deep Blue defeated the then world chess champion. In 2011, IBM Watson became the first non-human to win Jeopardy, which eventually led to a boom of deep neural models (and a resurgence of interest in AI, much like today) in 2012 (Frey, 1). </p>
<p><img alt="Fig 2: IBM Watson, on Jeopardy" src="./Generative AI in the Workforce_files/fig2.png"></p>
<p><em>Fig 2: IBM Watson, on Jeopardy (<a href="https://www.nytimes.com/2011/02/17/science/17jeopardy-watson.html">link</a>)</em></p>
<p>Generative AIs, as the name implies, are a subsection of AIs that can generate novel content based on the data it is trained on. Given the examples before, this content can be of any medium, with the most common being text-focused. Generative AIs aren't an entirely new invention - ELIZA can be considered to be a generative AI, and AARON (created in the 1970s) was a program that was able to create rudimentary line drawings (Frey, 5). Nonetheless, this characteristic of generative AIs could be why there is so much hype surrounding ChatGPT. We seem to have reached the point where it is possible to generate human creativity through a very unhuman-like machine. </p>
<p>We can think of AIs as tools that can help augment - or even replace - human labor. This concept is nothing new; the Industrial Revolution was defined by the creation of various machines that allowed people to automate work-intensive tasks (Zarifhonarvar, 102). Earlier AIs could be thought of as extensions of those machines: sure, they could perform a task better than a human could, but they needed to operate under explicit instructions. They lacked the human ingenuity to approach unseen circumstances or anything that wasn't already planned for by some engineer. This meant that throughout the decades, jobs that relied heavily on human creativity or even human common sense felt untouchable (Frey, 5). As such, AI didn't really "feel" like a threat to most jobs. </p>
<p>However, increasingly popular generative AI has flipped that sentiment around completely. Generative AIs (and really, any model trained through deep learning) can now identify patterns and give consistent outputs without needing explicit rules and guidelines for every edge case. In other words, all it takes to get a good human-like response is to feed our model enough data - so good, in fact, that ChatGPT in particular has passed the Turing Test (Frey, 2). Now, jobs that were thought to be safe from being replaced by AI are now no longer as untouchable. It isn't unreasonable to say that the vast majority of white-collar jobs have the potential to be augmented somehow through the use of generative AI. </p>
<p>That isn't to say that ChatGPT will end up replacing every job - far from it. And it definitely isn't to say that we will end up with a Skynet scenario where AI has taken over the world (it is much more likely for a human to severely abuse an AI for nefarious purposes than for an AI to "gain sentience"). In essence, ChatGPT is simply an incredibly good text predictor trained on billions of words. It doesn't have an actual "understanding" of the meaning behind each word the same way we humans do, and it is exceedingly poor at other tasks, such as computation (Atlas, 5). </p>
<p><img alt="Fig 3: ChatGPT gets a simple math question wrong" src="./Generative AI in the Workforce_files/fig3.png"></p>
<p><em>Fig 3: ChatGPT gets a simple math question wrong (<a href="https://community.openai.com/t/chatgpt-simple-math-calculation-mistake/62780">link</a>)</em></p>
<p>ChatGPT, and current AIs in general, is also incapable of "thinking outside the box," meaning that while it can create good solutions, it cannot create any novel solutions. In other words, AIs will only be able to output results that can be derived from the training data. This means that if you train your AI on data that represents all breadths of humanity (which should be done!), then that AI may simply have the capabilities of the average adult (Frey, 9). In this sense, ChatGPT is unable to reach the heights of human creativity: we cannot use it as a replacement for a researcher or to find new discoveries. In addition, because generative AIs are so dependent on the quality of their data, if you feed an generative AI biased data, it will likely give biased results. This, alongside the risk of possible hallucinations (where a generative AI outputs a ridiculous result), makes it hard to completely trust the output of a generative AI, especially if it isn't clear how the AI got to that output (Fui-Hoon, 4). </p>
<p>Of course, this doesn't mean that ChatGPT is unusable. ChatGPT can be used in cases where hallucinations and fact accuracy aren't of the utmost importance. For example, a common use of ChatGPT is "translation," namely, taking a crude idea or raw words and transforming them into an email, a report, a lesson plan, e.t.c (Atlas, 7). ChatGPT has also been used to reverse the process via summarization and condensing information. And as mentioned before, specialized GPTs can create certain types of content (songs, code, research reports) extremely well. Thus, even with some of the setbacks associated with generalized AIs, there are plenty of potential settings and opportunities for using them productively. </p>
<p><img alt="Fig 4: ChatGPT writing a thank you email, by the author" src="./Generative AI in the Workforce_files/fig4.png"></p>
<p><em>Fig 4: ChatGPT writing a thank you email, by the author</em></p>
<h2 id="what-are-the-potential-use-cases-of-generative-ai">What Are the Potential Use Cases of Generative AI?</h2>
<p>Given the wide variety of generative AIs already available, there are many proposed use cases for different industries. However, because of the problems mentioned in the previous section, and with the rapidly evolving field of AI, a lot of these use cases haven't been implemented yet. What's more, there is a general lack of policies and literacy in place to help support this integration (which hopefully this paper can help address!). Although there are a variety of different industry-specific use cases, generative AIs are good at replacing or augmenting extremely repetitive (but time-consuming) tasks, internal communication, and short-term people facing tasks (Zarifhonarar, 104). On the flip side, generative AI isn't the best where having a long-term personal connection is important (e.g. therapy). </p>
<p>To give you a sense of the extremely varied and complex potential of using generative AI in the workplace, I will go through a few major industries and describe what specific tasks AI can handle, how it can accomplish them, and potential challenges that may arise in implementing this. </p>
<p>For general marketing and business, generative AI will be especially good at creating personalized advertisements and promotions for the business's customers through multiple mediums. ChatGPT can also be used to perform analysis on how well that content is received, methods of reigning one's operation strategy (by understanding user behavior), deciding prices and methods of communicating those prices, and quality control (Ooi, 8). This process could potentially lead to an AI "arms race" between businesses for who could create the most accurate model, which could change how we fundamentally view content itself. </p>
<p>For healthcare and medical fields, generative AIs can be used to communicate important health information (such as diagnosis results) in a personable and accessible way, which can both increase patient trust and allow patients to make informed decisions (Fui-Hoon, 7). Generative AIs can also be used to support doctors by acting as a second opinion for essential clinical decisions, advise on different treatment options, help with image recognition for possible abnormalities, and help automate analysis. However, because a generative AI would need to be trained on personal medical information to be effective, there needs to be an ethical framework that balances AI efficiency with patient privacy and decision transparency (Al Naqbi). In addition, an AI may also come across as unempathetic and insincere. </p>
<p>For HR and training, generative AIs can be helpful for recruiters by highlighting key words, scanning through resumes, or performing extensive background checks to find candidates with a great fit through a somewhat objective lens. This could prove especially helpful for companies which require more background or supporting documents for recruitment (e.g. freelancing jobs). Generative AIs can also be used to train employees through personalized and colloquial coaching, which can both free up time for more experienced workers, while also allow for quicker appraisals of work (Ooi, 12). There is also potential for machine translations to tie teams of different cultural or geographic backgrounds (Al Naqbi). However, it may be beneficial to ensure that these systems remain transparent so that recruiters and trainers understand how the AI comes to the decisions it makes. </p>
<p>For academia and research, generative AIs can be used to make engaging and personalized lesson plans / assignments for students as a teaching assistant (not to mention potentially doubling as a tutor for one-on-one help), as well as grade written-based assignments (Atlas, 34). Researchers can use generative AIs to write reports, summarize papers, and proofread their findings. Nonetheless, there is the threat of students abusing generative AIs by becoming too reliant on the tool or flat out using the AI to do their schoolwork for them, threatening academic integrity (Fui-Hoon, 10). Rigorous guidelines should be in place to prevent such cases from happening. </p>
<p><img alt="Fig 5: Turnitin&#39;s advertise AI detector" src="./Generative AI in the Workforce_files/fig5.png"></p>
<p><em>Fig 5: Turnitin's advertise AI detector (<a href="https://www.turnitin.com/solutions/topics/ai-writing/">link</a>)</em></p>
<p>For engineering and technology creation, generative AIs can improve efficiency and safety throughout the engineering process, likely excelling at finding defects and streamlining human-machine interactions. Specific applications include early failure detection, increased disaster response rate, quicker product pipeline, and overall optimization (Al Naqbi). With all this in mind, what must make sure that their AI should augment, not replace, human skill by ensuring that workers do not get too reliant on using AI. </p>
<p>There are countless other industries that have their own use cases (e.g. banking with fraud detection, tourism for improving cultural communication, government with public sentiment measuring) (Ooi 24). However, not all occupations or industries will likely have the same degree of AI integration. For example, the occupations that are most likely going to see generative AI integration include telemarketing, humanities teachers, insurance, legal services, investing, and psychology (Felton, 8). These industries were calculated based on which human skills they generally favored, and how much those skills overlapped with natural language processing. On the flip side, we may not see as much overlap for more physical jobs, such as craft / trade works, agricultural jobs, and armed forces (Felton, 4). </p>
<p><img alt="Fig 6: Number of Occupations in ISCO database that are susceptible to GAI integration (Zarifhonarvar, 112)" src="./Generative AI in the Workforce_files/fig6.png"></p>
<p><em>Fig 6: Number of Occupations in ISCO database that are susceptible to GAI integration (Zarifhonarvar, 112)</em></p>
<p>With all this in mind, it should be stressed that the vast majority of these ideas have not been implemented in practice. Fortunately, there have been a few documented papers that touch upon workers' attitudes towards using generative AI in the workplace, as well as an instance where a company's productivity increased after using a generative AI chatbot. </p>
<h2 id="how-is-generative-ai-being-used-now">How Is Generative AI Being Used Now?</h2>
<p>Despite the hype currently surrounding ChatGPT and other generative AIs, there is little information on how ChatGPT is being adopted within formal work practices, not to mention very little organizational policy around using generative AIs (aside from outright banning it due to legal / security risks) (Cardon, 3). However, a survey conducted in March 2023 was able to get insight into how some workers felt about ChatGPT. Almost half of the survey participants believed that ChatGPT is a net good for society, with slightly more believing that it will be a net positive on job growth and productivity. Early adopters (workers who have used ChatGPT extensively before) were much more likely to hold favorable opinions compared to their counterparts (Cardon, 5). </p>
<p>A second follow-up study delved more into how professionals were using ChatGPT, how opinions changed based on managerial status and early adoption, and what were the perceived benefits of using generative AIs and having policies facilitating their use. Similar to the proposed uses in the section above, a fair amount of workers were using ChatGPT to generate ideas, draft texts for messages and other documents, proofreading, and summarizing text (Cardon, 7). In particular, executives were much more likely to engage in these tasks compared to non-managerial workers, hinting that ChatGPT may be well suited for internal communication. </p>
<p>Similar to the previous survey, a little more than half of the workers believed that ChatGPT helps with the efficiency and quality of the work. Both executive level and early adopters were much more likely to have favorable opinions of ChatGPT in this sense, and vice versa (executives in particular were 20% more likely to say that ChatGPT made them more efficient) (Cardon, 8). As for organizational practices, workers that already had policies in place addressing ChatGPT use were more likely to believe that the policies led to improved trust, more efficiency, robust legal protections, and ease of use (Cardon, 12). Workers that did not have the policy had more neutral views, though early adopters still had a slightly positive outlook. </p>
<p><img alt="Fig 7: Survey opinions on ChatGPT and work efficiency by managerial and early adopter status (Cardon, 8)" src="./Generative AI in the Workforce_files/fig7.png"></p>
<p><em>Fig 7: Survey opinions on ChatGPT and work efficiency by managerial and early adopter status (Cardon, 8)</em></p>
<p>Altogether, there are a sizable number of people who believe that ChatGPT can play a beneficial role in the workplace, namely by improving work efficiency and quality. While it is clear that those who are more experienced with ChatGPT are likely to recommend using it, they are also likely to want workplace policies that define when and how to use ChatGPT. This could point towards a growing need for AI literacy in order to use it effectively and confidently. What's more, a non insignificant percentage of workers are using it to supplement their work (including executives), which could make stronger policies that promote innovation, efficiency, and legality essential (Fui-Hoon, 17). </p>
<p>Although there are not many documented experiments that show empirical evidence that a generative AI tool has helped increase workplace efficiency, a study conducted in 2023 has shown such results. A Fortune 500 data firm gave their customer support team (a team which was notorious for having a high employee turnaround and outsourcing rate) a generative AI powered tool that would offer employees suggestions on how to respond to customer chats (Brynjolfsson, 9). Suggestions were only given when there was sufficient enough training data to avoid any possible hallucinations, and workers had the ultimate choice of choosing whether to follow a suggestion or not. The AI itself was trained on numerous customer support tickets, prioritizing chats that were resolved with quick, empathetic, and professional responses (Brynjolfsson, 11). Efficiency was measured by a combination of how many tickets were resolved per hour, the number of tickets that were addressed concurrently, and the percentage of tickets that were resolved favorably. </p>
<p><img alt="Fig 8: Example of generative AI suggestion (Brynjolfsson, 34)" src="./Generative AI in the Workforce_files/fig8.png"></p>
<p><em>Fig 8: Example of generative AI suggestion (Brynjolfsson, 34)</em></p>
<p>Two groups were made: one that did not receive access to the tool at all, and one that was given access after a few weeks. The experiment found that using the tool allowed workers to not only increase the number of chats they completed per hour, but also increase the number of chats they could work on simultaneously (pointing towards faster completion and better multitasking). Interestingly enough, the lowest quintile in terms of worker performance saw the highest increase in ticket resolutions per hour (+34%), while the best performing quintile actually saw a slight decrease; this could imply that the generative AI may actually be distracting or forcing the workers into choosing less than optimal answers. A similar effect can also be seen on tenure, where workers that had less than 1 month’s worth of experience saw their efficiency increase by 46% (Brynjolfsson, 15). Furthermore, workers that had access to the tool saw their efficiency dramatically increase in the weeks that directly followed their first use. This implies that the use of the generative AI tool had allowed workers to get ahead of the learning curve much faster than workers who could not use the tool (Brynjolfsson, 17). </p>
<p><img alt="Fig 9: Average Change in Resolutions Per Hour By Agent Skill (Brynjolfsson, 38)" src="./Generative AI in the Workforce_files/fig9.png"></p>
<p><em>Fig 9: Average Change in Resolutions Per Hour By Agent Skill (Brynjolfsson, 38)</em></p>
<p>The study also found that workers retained their increased skill after using the generative AI tool. Not only did the rate of accepting the suggested response (possibly hinting at a lessening of skepticism) increase over time for all workers, but workers were still able to achieve heightened success even when outages prevented them from using the tool (Brynjolfsson, 21). This can point to evidence that workers were able to learn and retain some skill from using the AI tool. This could be because the tool gave real-time, constant feedback, while workers in the control group only got feedback through weekly one-on-one sessions with their managers, which were usually short and prone to human error. Moreover, chat sessions done by lower skill workers became closer in-line with what higher skill workers were writing (computed using cosine similarity) (Brynjolfsson, 22). </p>
<p>As such, this experiment provides ample evidence generative AI had a positive effect on the workplace far beyond simply increasing efficiency when using the tool. The chatbot had allowed less experienced workers to quickly pick up and understand the best responses for a variety of customer situations, which likely would have only been accomplished by working with more experienced members or through the weekly meetings. This skill learning was proven to be durable, as workers were able to consistently apply what they've learned even without the tool. As such, we can expect that one promising role that generative AI can play is in training newer workers to use company best practices, as opposed to a tool that can augment some of the best performers.</p>
<h2 id="why-hasnt-generative-ai-caught-on-in-the-workplace-yet">Why Hasn't Generative AI Caught On In the Workplace Yet?</h2>
<p>Even with the various proposed use cases for generative AI in the workplace, as well as actual evidence of such tools improving workplace efficiency, there is still a fair amount of push back against using generative AI tools in their current state - and with good reason. Given how quickly this field has evolved, and with all the new tools being corrected, workplace guidelines and even general AI literacy has not caught up with our advancements (Zarifhonarvar, 107). In a sense, we have a lot of research and papers done on different AI techniques, but not so much on the actual applications of these tools. Furthermore, a lot of the current research focuses primarily on a specific tool such as ChatGPT; this makes it hard to use their findings whenever we inevitably get stronger tools. In other words, focusing on topics such as prompt engineering distracts us from the main drawbacks of using generative AI (Fui-Hoon, 13). </p>
<p>At its core, a lot of the problems associated with generative AI can be traced back to the data that it is trained on. In many cases, when an AI gives a biased or inappropriate answer, it isn't because there is something malevolent or incorrect in the model structure. Rather, the data that the AI is trained on may have some biases baked into it; a common problem is when the training data isn't representative of the actual population it draws from (Fui-Hoon, 12). What's worse is that this could be a feedback loop that reinforces certain stereotypes, especially when content from one generative AI gets included in training data for another AI. </p>
<p>A major reason why this is a pervasive problem is because generative AIs are increasingly being trained on larger datasets (Frey, 3). It becomes exceedingly hard to ensure that all data is clean and representative when training data can be as large as the entirety of Wikipedia. Of course, bigger datasets means more training time needed to process everything, which translates to higher fiscal and environmental costs. Furthermore, bigger datasets aren't going to guarantee better output accuracy or eliminate the problem of hallucinations (i.e. the AI giving an entirely incorrect answer) (Frey, 4). Alongside physical constraints, it seems that we will eventually reach a ceiling of how accurate our generative AI is, and many may not think that using the AI is worth the constant babysitting and output fact-checking. </p>
<p><img alt="Fig 10: Increase in parameter size in subsequent ChatGPT models" src="./Generative AI in the Workforce_files/fig10.png"></p>
<p><em>Fig 10: Increase in parameter size in subsequent ChatGPT models (<a href="https://www.stylefactoryproductions.com/blog/chatgpt-statistics">link</a>)</em></p>
<p>AI models as a whole lack a certain degree of transparency, as it is not always understandable how a machine gave the output it came up with. Many natural language algorithms use word embeddings (a vector of numbers) instead of the word itself, which humans cannot interpret. This adds another layer of why it may be hard to trust the output of an AI tool; whereas we can easily ask a human how they came up with their solution, we cannot do the same with an algorithm. As such, companies may be reluctant to deploy generative AI tools in situations where details do matter, including in healthcare and financial sectors (Al-Naqbi). Another problem that goes hand-in-hand with lack of transparency are possible security risks. An employee using an open-source AI tool may feed it a prompt with private company data, which may be used to further train the model. In another scenario, a worker may accidentally use content that has been trained on copyrighted materials (a legally dubious situation that most companies avoid) (Fui-Hoon, 14). </p>
<p>Finally, one of the biggest problems about using a generative AI tool may not have anything to do with the model itself. Rather, users who are unaware of the problems mentioned above (or even the actual nature of generative AIs itself) could end up blindly trusting whatever it generates (Fui-Hoon, 8). Not only could this lead to workers forgoing their own skills in favor of becoming reliant on the generative AI tool, but it can also perpetuate biases in the training data. This may also lead to companies implementing generative AI tools in areas that are simply better off without them, either because the stakes of failure are too high, or because the tool may hamper the human worker's abilities (Frey, 8). </p>
<p>These are all very pressing problems that should be addressed before we can embrace generative AI in the workplace. Fortunately, there are some promising solutions that could alleviate these problems. For one, having rigorous guidelines in place can prevent the misuse of generative AI and avoid murky situations of using copyrighted material or leaking company data (Zarifhonarvar, 110). Encouraging better transparency in the data collection stage can also increase people's trust in the generative AI content, as the public would have a better idea of where the AI gets its data from and any potential biases within that data. </p>
<h2 id="what-is-the-future-of-generative-ai">What is the Future of Generative AI?</h2>
<p>Generative AI is here to stay. While I can't answer how generative AIs will technically progress, I believe that we will start to see more conversations shift towards how we can profit off of generative AIs. Even with clear evidence that AI could be a positive force in increasing productivity, we need to make sure that doesn't come with the detriment of something else, such as morality or model reliability. Though there are many logistical and ethical hurdles to overcome, there is ample opportunity for integrating generative AI tools within the work pipeline across a variety of occupations. Above all, we must ensure generative AI augments human ability, rather than hamper or completely replace it. </p>
<p>To do so, as mentioned in the section before, we need to have policies and regulations in place to ensure that these tools are being used for the common good. While generative AI does have the potential of making certain jobs obsolete, we should instead be tuning our tools to complement our abilities. Doing so could even lead to the creation of more jobs, such as workers who ensure no outages take place. Evidence has shown that there are ways to implement these tools that could be used to both increase efficiency and improve how workers perform, but there are possible drawbacks that need to be avoided. Ideally, companies should start with gradual integrations in low-scale tasks with plenty of oversight. Internal communication, training, and repetitive paperwork could be good places to start. </p>
<p>All in all, what I hope to instill is that there is great, great potential in generative AI. It can wholeheartedly have its place within a business, but we need to ensure that we have policies in place to accommodate it. In the near future, we may see many industries and sectors be revolutionized by generative AI tools, and ultimately be a force for good. </p>
<h2 id="bibliography">Bibliography</h2>
<p>Al Naqbi, Humaid, Zied Bahroun, and Vian Ahmed. "Enhancing Work Productivity through Generative Artificial Intelligence: A Comprehensive Literature Review." Sustainability 16.3 (2024): 1166.</p>
<p>Atlas, Stephen. "ChatGPT for higher education and professional development: A guide to conversational AI." (2023).</p>
<p>Brynjolfsson, Erik, Danielle Li, and Lindsey R. Raymond. Generative AI at work. No. w31161. National Bureau of Economic Research, 2023.</p>
<p>Cardon, Peter W., et al. "Generative AI in the Workplace: Employee Perspectives of Chatgpt Benefits and Organizational Policies." SocArXiv, 18 Mar. 2023. Web.</p>
<p>Felten, Ed, Manav Raj, and Robert Seamans. "How will language modelers like chatgpt affect occupations and industries?." arXiv preprint arXiv:2303.01157 (2023).</p>
<p>Frey, Carl Benedikt, and Michael Osborne. "Generative AI and the future of work: a reappraisal." Brown Journal of World Affairs 30.1 (2023): 1-17.</p>
<p>Fui-Hoon Nah, Fiona, et al. "Generative AI and ChatGPT: Applications, challenges, and AI-human collaboration." Journal of Information Technology Case and Application Research 25.3 (2023): 277-304.</p>
<p>Ooi, Keng-Boon, et al. "The potential of generative artificial intelligence across disciplines: Perspectives and future directions." Journal of Computer Information Systems (2023): 1-32.</p>
<p>Zarifhonarvar, Ali. "Economics of chatgpt: A labor market view on the occupational impact of artificial intelligence." Journal of Electronic Business &amp; Digital Economics (2023).</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="./Generative AI in the Workforce_files/bootstrap.bundle.min.js.download"></script>
        <script>
            var base_url = ".",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="./Generative AI in the Workforce_files/base.js.download"></script>
        <script src="./Generative AI in the Workforce_files/main.js.download"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" aria-labelledby="searchModalLabel" aria-hidden="true" style="display: none;">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"><p>No results found</p></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table table-striped table-hover">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    <script>
var livereload = function(epoch, requestId) {
    var req, timeout;

    var poll = function() {
        req = new XMLHttpRequest();
        req.onloadend = function() {
            if (parseFloat(this.responseText) > epoch) {
                location.reload();
            } else {
                timeout = setTimeout(poll, this.status === 200 ? 0 : 3000);
            }
        };
        req.open("GET", "/livereload/" + epoch + "/" + requestId);
        req.send();
    }

    var stop = function() {
        if (req) {
            req.abort();
        }
        if (timeout) {
            clearTimeout(timeout);
        }
        req = timeout = undefined;
    };

    window.addEventListener("load", function() {
        if (document.visibilityState === "visible") {
            poll();
            
        }
    });
    window.addEventListener("visibilitychange", function() {
        if (document.visibilityState === "visible") {
            poll();
        } else {
            stop();
        }
    });
    window.addEventListener("beforeunload", stop);
    document.addEventListener('DOMContentLoaded', Nutshell.start(h2));

    console.log('Enabled live reload');
}
livereload(81807765, 81808921);
</script>



</body></html>